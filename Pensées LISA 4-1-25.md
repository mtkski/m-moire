#pensées 
___

J'ai maintenant une relativement bonne connaissance de ce qui se fait en computation 3D, en représentation de scènes implicites (NeRF, GS, SIRENs), et je comprends plutôt bien tout les outils et concepts autour de ça, je serais intéressé de parler de l'état des recherches à l'ULB sur tout ça à Mr. Debeir ou Lafruit. Parce que sur papier c'est pleins de choses qui seraient intéressantes pour le labo LISA, mais j'ai l'impression que ça focus sur des techno pas les plus actuelles. Demander quel est le fuck avec les _plenoptic cameras_. Pour faire des outils de représentation "bas-relief" 3D, pourquoi ne pas focus sur des technologies plus accessibles au grand public et, par exemple, optimiser des algos et technique de _structure from motion_ ou d'estimation de depth map (DERS du projet MPEG). 
RLC est très impressionnant techniquement , mais quel est le but de travailler sur la compression de ces multi-vues ? Malgré l'argument de contribuer au _standard_ avec MPEG, aucun but commercial, pas de réel impact ou intérêt pour ce genre de choses, un peu comme la 3D de la 3DS ou des smart TV. J'ai l'impression que l'idée principale c'est de regarder une video en VR, ou sur un écran volumétrique (je pense bien que c'était le nom des écrans à étages sur lesquels Brenno a bossé) et avoir un petit effet de profondeur. Pourquoi focus sur les cameras plenoptic alors que pour moi c'est loin d'être une technologie aboutie et grand public. 

Les contre-arguments que je peux y voir, ça serait que
1) c'est pas abouti pcq personne bosse dessus, donc go dév tout ça, 
2) ça s'utilise (ou se vendra) comme une "expérience", une prouesse technique d'un écran capable d'avoir réellement un effet de profondeur sans le côté mal aux yeux de la 3D. 
3) il y a des cas d'utilisation que je ne capte juste pas, 

D'ailleurs, en parlant d'écran volumétrique, le projet de Brenno était trop intéressant, il faut que je lui demande s'il a encore le paper qu'il a écrit. Je sais plus s'il était question d'un shader ou d'autre chose, mais le côté représentation de 3 vues sur 3 écrans séparés et leur 3 images qui se blend pour n'en faire qu'une est quelque chose qui est fort relié aux _GS_ ou aux _NeRFs_. Ça aurait pu faire un bon mémoire ça, l'utilisation de Gaussiennes comme méthode de rendering sur ce genre d'écran. 
